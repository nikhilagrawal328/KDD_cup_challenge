{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KDD Cup 2009 Orange Customer Relationships</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " KDD Cup is the annual Data Mining and Knowledge Discovery competition organized by ACM Special Interest Group on Knowledge Discovery and Data Mining, the leading professional organization of data miners.\n",
    "\n",
    " In the The KDD Cup 2009, a large marketing databases from the French Telecom company Orange had been offered to work on to predict the propensity of customers to\n",
    "\n",
    "- switch provider (churn),\n",
    "- buy new products or services (appetency),\n",
    "- make the sale more profitable (up-selling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, there are all meaningless header names for the features. That's why we need to understand the relations between those features. The most important point for the analysis is to visualise these relations and put a theory that these relations fit in. We shall clean the data first and visualise. Later with the right questions and analysing those questions, we can find the right model for the best performance for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import initializers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Input, Embedding, Lambda, Dropout, Activation, Reshape, GlobalAveragePooling1D, merge, Flatten, Bidirectional, CuDNNGRU, add, Conv1D, GlobalMaxPooling1D,MaxPooling1D\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\abc\\\\Code_base'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing directory\n",
    "os.chdir('C:/Users/abc/Documents/kdd 2019')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_table('orange_small_train.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 230)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>fXVEsaq</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>NKv4yOc</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1J2cvxe</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN  1526.0   7.0   NaN   NaN    NaN  ...   \n",
       "1   NaN   NaN   NaN   NaN   NaN   525.0   0.0   NaN   NaN    NaN  ...   \n",
       "2   NaN   NaN   NaN   NaN   NaN  5236.0   7.0   NaN   NaN    NaN  ...   \n",
       "3   NaN   NaN   NaN   NaN   NaN     NaN   0.0   NaN   NaN    NaN  ...   \n",
       "4   NaN   NaN   NaN   NaN   NaN  1029.0   7.0   NaN   NaN    NaN  ...   \n",
       "\n",
       "    Var221   Var222      Var223  Var224  Var225  Var226   Var227  \\\n",
       "0     oslk  fXVEsaq  jySVZNlOJy     NaN     NaN    xb3V     RAYp   \n",
       "1     oslk  2Kb5FSF  LM8l689qOp     NaN     NaN    fKCe     RAYp   \n",
       "2  Al6ZaUT  NKv4yOc  jySVZNlOJy     NaN    kG3k    Qu4f  02N6s8f   \n",
       "3     oslk  CE7uk3u  LM8l689qOp     NaN     NaN    FSa2     RAYp   \n",
       "4     oslk  1J2cvxe  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "\n",
       "          Var228  Var229  Var230  \n",
       "0  F2FyR07IdsN7I     NaN     NaN  \n",
       "1  F2FyR07IdsN7I     NaN     NaN  \n",
       "2  ib5G6X1eUxUn6    am7c     NaN  \n",
       "3  F2FyR07IdsN7I     NaN     NaN  \n",
       "4  F2FyR07IdsN7I    mj86     NaN  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading the data\n",
    "'''\n",
    "train = pd.read_table('orange_small_train.data')\n",
    "train.head() # printing first few 5 rows\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# loading the target variable appetency\n",
    "appetency = pd.read_table('orange_small_train_appetency.labels', header = None).loc[:, 0].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of rows\n",
    "appetency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \n",
      "C:\\Users\\abc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# loading the target variable churn and upselling\n",
    "churn = pd.read_table('orange_small_train_churn.labels', header = None,sep='\\t').loc[:, 0].astype('category')\n",
    "upselling= pd.read_table('orange_small_train_upselling.labels', header = None,sep='\\t').loc[:, 0].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting bar plot of target values\n",
    "appetency.value_counts().plot.bar()\n",
    "plt.ylabel('value')\n",
    "plt.title('appetency value for each class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "churn.value_counts().plot.bar()\n",
    "plt.ylabel('value')\n",
    "plt.title('churn value for each class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "upselling.value_counts().plot.bar()\n",
    "plt.ylabel('value')\n",
    "plt.title('upselling value for each class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above 3 plots shows that data is highly unbalanced so we should apply oversampling to balance the data while modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    if train[i].isnull().sum()/len(train)>=1.0:\n",
    "        train.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 212)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Var73']=train['Var73'].astype('float',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Var73'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the datatype of features\n",
    "DataVars = train.columns\n",
    "data_types = {Var: train[Var].dtype for Var in DataVars}\n",
    "\n",
    "for Var in DataVars:\n",
    "    if data_types[Var] == int:\n",
    "        x = train[Var].astype(float)\n",
    "        train.loc[:, Var] = x\n",
    "        data_types[Var] = x.dtype\n",
    "    elif data_types[Var] != float:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x = train[Var].astype('category')\n",
    "        train.loc[:, Var] = x\n",
    "        data_types[Var] = x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 212 entries, Var1 to Var229\n",
      "dtypes: category(38), float64(174)\n",
      "memory usage: 72.0 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all the float datatype features\n",
    "float_DataVars = [Var for Var in DataVars if data_types[Var] == float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_x_means = train.mean()\n",
    "\n",
    "for Var in float_DataVars:\n",
    "    x = train[Var]\n",
    "    mediancol=train[Var].mean()\n",
    "    isThereMissing = x.isnull()\n",
    "    if isThereMissing.sum() > 0:\n",
    "        train.loc[isThereMissing.tolist(), Var] = float_x_means[Var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all the categpry features\n",
    "DataVars = train.columns\n",
    "\n",
    "categorical_DataVars = [Var for Var in DataVars if data_types[Var] != float]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_levels = train[categorical_DataVars].apply(lambda col: len(col.cat.categories))\n",
    "categorical_x_var_names = categorical_levels[categorical_levels > 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var191        1\n",
       "Var192      361\n",
       "Var193       51\n",
       "Var194        3\n",
       "Var195       23\n",
       "Var196        4\n",
       "Var197      225\n",
       "Var198     4291\n",
       "Var199     5073\n",
       "Var200    15415\n",
       "Var201        2\n",
       "Var202     5713\n",
       "Var203        5\n",
       "Var204      100\n",
       "Var205        3\n",
       "Var206       21\n",
       "Var207       14\n",
       "Var208        2\n",
       "Var210        6\n",
       "Var211        2\n",
       "Var212       81\n",
       "Var213        1\n",
       "Var214    15415\n",
       "Var215        1\n",
       "Var216     2016\n",
       "Var217    13990\n",
       "Var218        2\n",
       "Var219       22\n",
       "Var220     4291\n",
       "Var221        7\n",
       "Var222     4291\n",
       "Var223        4\n",
       "Var224        1\n",
       "Var225        3\n",
       "Var226       23\n",
       "Var227        7\n",
       "Var228       30\n",
       "Var229        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceInfrequentLevels(data, val=0.015):\n",
    "    collapsed_categories = {}\n",
    "    for categorical_x_var_name in categorical_x_var_names:\n",
    "        x = data[categorical_x_var_name].copy()\n",
    "        for category in x.cat.categories:\n",
    "            matching_rows_yesno = x == category\n",
    "            if matching_rows_yesno.sum() < val * data.shape[0]:\n",
    "                if categorical_x_var_name in collapsed_categories:\n",
    "                    collapsed_categories[categorical_x_var_name].append(category)\n",
    "                else:\n",
    "                    collapsed_categories[categorical_x_var_name] = [category]\n",
    "                if 'OTHER' not in data[categorical_x_var_name].cat.categories:\n",
    "                    data[categorical_x_var_name].cat.add_categories('OTHER', inplace=True)\n",
    "                data.loc[matching_rows_yesno, categorical_x_var_name] = 'OTHER'\n",
    "                data[categorical_x_var_name].cat.remove_categories(category, inplace=True)\n",
    "    return data            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= replaceInfrequentLevels(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values within categorical features after preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Var192     1\n",
       "Var193     4\n",
       "Var195     3\n",
       "Var197     8\n",
       "Var198     4\n",
       "Var199     4\n",
       "Var200     1\n",
       "Var202     1\n",
       "Var204    23\n",
       "Var206    12\n",
       "Var207     7\n",
       "Var212     7\n",
       "Var214     1\n",
       "Var216    13\n",
       "Var217     1\n",
       "Var219     5\n",
       "Var220     4\n",
       "Var222     4\n",
       "Var226    22\n",
       "Var228    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_x_nb_levels = train[categorical_x_var_names].apply(lambda col: len(col.cat.categories))\n",
    "print(\"Number of unique values within categorical features after preprocessing:\")\n",
    "categorical_x_nb_levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var192    0.00738\n",
      "Var193    0.00000\n",
      "Var195    0.00000\n",
      "Var197    0.00286\n",
      "Var198    0.00000\n",
      "Var199    0.00008\n",
      "Var200    0.50816\n",
      "Var202    0.00002\n",
      "Var204    0.00000\n",
      "Var206    0.11058\n",
      "Var207    0.00000\n",
      "Var212    0.00000\n",
      "Var214    0.50816\n",
      "Var216    0.00000\n",
      "Var217    0.01406\n",
      "Var219    0.10422\n",
      "Var220    0.00000\n",
      "Var222    0.00000\n",
      "Var226    0.00000\n",
      "Var228    0.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[categorical_x_var_names].isnull().sum()/len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_var_name in categorical_x_var_names:\n",
    "    train[categorical_var_name].cat.add_categories(\"unknown_\"+categorical_var_name, inplace=True)\n",
    "    train[categorical_var_name].fillna(\"unknown_\"+categorical_var_name, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values per Categorical feature after preprocessing:\n",
      "Var192    0.0\n",
      "Var193    0.0\n",
      "Var195    0.0\n",
      "Var197    0.0\n",
      "Var198    0.0\n",
      "Var199    0.0\n",
      "Var200    0.0\n",
      "Var202    0.0\n",
      "Var204    0.0\n",
      "Var206    0.0\n",
      "Var207    0.0\n",
      "Var212    0.0\n",
      "Var214    0.0\n",
      "Var216    0.0\n",
      "Var217    0.0\n",
      "Var219    0.0\n",
      "Var220    0.0\n",
      "Var222    0.0\n",
      "Var226    0.0\n",
      "Var228    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of missing values per Categorical feature after preprocessing:\")\n",
    "print(train[categorical_x_var_names].isnull().sum()/len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var191',\n",
       " 'Var192',\n",
       " 'Var193',\n",
       " 'Var194',\n",
       " 'Var195',\n",
       " 'Var196',\n",
       " 'Var197',\n",
       " 'Var198',\n",
       " 'Var199',\n",
       " 'Var200',\n",
       " 'Var201',\n",
       " 'Var202',\n",
       " 'Var203',\n",
       " 'Var204',\n",
       " 'Var205',\n",
       " 'Var206',\n",
       " 'Var207',\n",
       " 'Var208',\n",
       " 'Var210',\n",
       " 'Var211',\n",
       " 'Var212',\n",
       " 'Var213',\n",
       " 'Var214',\n",
       " 'Var215',\n",
       " 'Var216',\n",
       " 'Var217',\n",
       " 'Var218',\n",
       " 'Var219',\n",
       " 'Var220',\n",
       " 'Var221',\n",
       " 'Var222',\n",
       " 'Var223',\n",
       " 'Var224',\n",
       " 'Var225',\n",
       " 'Var226',\n",
       " 'Var227',\n",
       " 'Var228',\n",
       " 'Var229']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=[]\n",
    "for i in train.columns:\n",
    "    if train[i].dtypes!=float:\n",
    "        lst.append(i)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = pd.get_dummies(train, columns=['Var191',\n",
    " 'Var192',\n",
    " 'Var193',\n",
    " 'Var194',\n",
    " 'Var195',\n",
    " 'Var196',\n",
    " 'Var197',\n",
    " 'Var198',\n",
    " 'Var199',\n",
    " 'Var200',\n",
    " 'Var201',\n",
    " 'Var202',\n",
    " 'Var203',\n",
    " 'Var204',\n",
    " 'Var205',\n",
    " 'Var206',\n",
    " 'Var207',\n",
    " 'Var208',\n",
    " 'Var210',\n",
    " 'Var211',\n",
    " 'Var212',\n",
    " 'Var213',\n",
    " 'Var214',\n",
    " 'Var215',\n",
    " 'Var216',\n",
    " 'Var217',\n",
    " 'Var218',\n",
    " 'Var219',\n",
    " 'Var220',\n",
    " 'Var221',\n",
    " 'Var222',\n",
    " 'Var223',\n",
    " 'Var224',\n",
    " 'Var225',\n",
    " 'Var226',\n",
    " 'Var227',\n",
    " 'Var228',\n",
    " 'Var229'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var228_Zy3gnGM</th>\n",
       "      <th>Var228_ib5G6X1eUxUn6</th>\n",
       "      <th>Var228_iyHGyLCEkQ</th>\n",
       "      <th>Var228_xwM2aC7IdeMC0</th>\n",
       "      <th>Var228_OTHER</th>\n",
       "      <th>Var228_unknown_Var228</th>\n",
       "      <th>Var229_am7c</th>\n",
       "      <th>Var229_mj86</th>\n",
       "      <th>Var229_oJmt</th>\n",
       "      <th>Var229_sk2h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.487179</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>425.298387</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>238793.32885</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48.145299</td>\n",
       "      <td>392605.656355</td>\n",
       "      <td>8.625806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.487179</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>425.298387</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>238793.32885</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.145299</td>\n",
       "      <td>392605.656355</td>\n",
       "      <td>8.625806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.487179</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>425.298387</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>238793.32885</td>\n",
       "      <td>5236.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48.145299</td>\n",
       "      <td>392605.656355</td>\n",
       "      <td>8.625806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.487179</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>425.298387</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>238793.32885</td>\n",
       "      <td>1326.437116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.145299</td>\n",
       "      <td>392605.656355</td>\n",
       "      <td>8.625806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.487179</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>425.298387</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>238793.32885</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48.145299</td>\n",
       "      <td>392605.656355</td>\n",
       "      <td>8.625806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Var1      Var2        Var3      Var4          Var5         Var6  Var7  \\\n",
       "0  11.487179  0.004029  425.298387  0.125396  238793.32885  1526.000000   7.0   \n",
       "1  11.487179  0.004029  425.298387  0.125396  238793.32885   525.000000   0.0   \n",
       "2  11.487179  0.004029  425.298387  0.125396  238793.32885  5236.000000   7.0   \n",
       "3  11.487179  0.004029  425.298387  0.125396  238793.32885  1326.437116   0.0   \n",
       "4  11.487179  0.004029  425.298387  0.125396  238793.32885  1029.000000   7.0   \n",
       "\n",
       "        Var9          Var10     Var11  ...  Var228_Zy3gnGM  \\\n",
       "0  48.145299  392605.656355  8.625806  ...               0   \n",
       "1  48.145299  392605.656355  8.625806  ...               0   \n",
       "2  48.145299  392605.656355  8.625806  ...               0   \n",
       "3  48.145299  392605.656355  8.625806  ...               0   \n",
       "4  48.145299  392605.656355  8.625806  ...               0   \n",
       "\n",
       "   Var228_ib5G6X1eUxUn6  Var228_iyHGyLCEkQ  Var228_xwM2aC7IdeMC0  \\\n",
       "0                     0                  0                     0   \n",
       "1                     0                  0                     0   \n",
       "2                     1                  0                     0   \n",
       "3                     0                  0                     0   \n",
       "4                     0                  0                     0   \n",
       "\n",
       "   Var228_OTHER  Var228_unknown_Var228  Var229_am7c  Var229_mj86  Var229_oJmt  \\\n",
       "0             0                      0            0            0            0   \n",
       "1             0                      0            0            0            0   \n",
       "2             0                      0            1            0            0   \n",
       "3             0                      0            0            0            0   \n",
       "4             0                      0            0            1            0   \n",
       "\n",
       "   Var229_sk2h  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 388 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1.to_csv('train_cust2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1=pd.read_csv('train_cust2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking target variable as churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(train_data_1,churn, stratify=churn, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train, test):\n",
    "\n",
    "\n",
    "    mean = np.mean(train, axis=0)\n",
    "    std = np.std(train, axis=0)+0.000001\n",
    "\n",
    "    X_train = (train - mean) / std\n",
    "    X_test = (test - mean) /std\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_cv, y_train, y_cv = train_test_split(X_train,y_train, stratify=y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HyperParameter:  {'max_depth': 5, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "random_classifier = RandomForestClassifier()\n",
    "\n",
    "parameters = { 'max_depth':np.arange(5,10),'n_estimators':list(range(75,301,25))}\n",
    "\n",
    "random_grid = GridSearchCV(random_classifier, parameters, cv = 3)\n",
    "\n",
    "random_grid.fit(X_cv, y_cv)\n",
    "\n",
    "print(\"Best HyperParameter: \",random_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=75, n_jobs=-1, oob_score=True, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=75,\n",
    "    #criterion='entropy',\n",
    "    max_depth=5,   # expand until all leaves are pure or contain < MIN_SAMPLES_SPLIT samples\n",
    "    #min_samples_split=100,\n",
    "    #min_samples_leaf=50,\n",
    "    #min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,   # number of features to consider when looking for the best split; None: max_features=n_features\n",
    "    max_leaf_nodes=None,   # None: unlimited number of leaf nodes\n",
    "    bootstrap=True,\n",
    "    oob_score=True,   # estimate Out-of-Bag Cross Entropy\n",
    "    n_jobs=-1,   # paralellize over all CPU cores but 2\n",
    "    class_weight='balanced',    # our classes are skewed, but but too skewed\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "rf_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6766423881453841"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred_probs=rf_model.predict(X_train)\n",
    "auc=metrics.roc_auc_score(y_train,rf_pred_probs)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6409505378721893"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred_probs=rf_model.predict(X_test)\n",
    "auc=metrics.roc_auc_score(y_test,rf_pred_probs)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var126', 'Var212_NhsEn4L', 'Var73', 'Var189', 'Var217_OTHER', 'Var74',\n",
       "       'Var113', 'Var140', 'Var217_unknown_Var217', 'Var81', 'Var28', 'Var125',\n",
       "       'Var13', 'Var57', 'Var210_g5HH', 'Var218_cJvF', 'Var6', 'Var210_uKAI',\n",
       "       'Var153', 'Var94', 'Var205_sJzTlal', 'Var45', 'Var216_7WwuNea', 'Var38',\n",
       "       'Var134', 'Var204_z5Ry', 'Var76', 'Var83', 'Var51', 'Var163',\n",
       "       'Var193_RO12', 'Var24', 'Var160', 'Var119', 'Var112', 'Var149',\n",
       "       'Var109', 'Var44', 'Var123', 'Var205_VpdQ', 'Var144', 'Var7', 'Var188',\n",
       "       'Var35', 'Var25', 'Var65', 'Var21', 'Var195_taul', 'Var133', 'Var22',\n",
       "       'Var212_XfqtO3UdzaXh_', 'Var205_09_Q', 'Var218_UYBR', 'Var228_OTHER',\n",
       "       'Var107', 'Var226_szEZ', 'Var199_OTHER', 'Var206_OTHER', 'Var85',\n",
       "       'Var229_am7c', 'Var204_m_h1', 'Var216_mAjbk_S', 'Var226_3Cy4', 'Var82',\n",
       "       'Var219_FzaX', 'Var72', 'Var226_wX53', 'Var117', 'Var197_lK27',\n",
       "       'Var226_me1d', 'Var227_ZI9m', 'Var193_OTHER', 'Var197_TyGl', 'Var84',\n",
       "       'Var226_7P5s', 'Var59', 'Var68', 'Var200_unknown_Var200',\n",
       "       'Var207_me75fM6ugJ', 'Var211_L84s', 'Var226_Qcbd', 'Var206_lVqb',\n",
       "       'Var10', 'Var216_kq0n8Bj', 'Var195_OTHER', 'Var95',\n",
       "       'Var219_unknown_Var219', 'Var152', 'Var154', 'Var223_M_8D',\n",
       "       'Var225_xG3x', 'Var46', 'Var216_kq0aHkC', 'Var139', 'Var211_Mtgm',\n",
       "       'Var214_unknown_Var214', 'Var223_jySVZNlOJy', 'Var36', 'Var198_iJzviRg',\n",
       "       'Var158'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances[:100].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Feature Selection using Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1=train_data_1[['Var126', 'Var212_NhsEn4L', 'Var73', 'Var189', 'Var217_OTHER', 'Var74',\n",
    "       'Var113', 'Var140', 'Var217_unknown_Var217', 'Var81', 'Var28', 'Var125',\n",
    "       'Var13', 'Var57', 'Var210_g5HH', 'Var218_cJvF', 'Var6', 'Var210_uKAI',\n",
    "       'Var153', 'Var94', 'Var205_sJzTlal', 'Var45', 'Var216_7WwuNea', 'Var38',\n",
    "       'Var134', 'Var204_z5Ry', 'Var76', 'Var83', 'Var51', 'Var163',\n",
    "       'Var193_RO12', 'Var24', 'Var160', 'Var119', 'Var112', 'Var149',\n",
    "       'Var109', 'Var44', 'Var123', 'Var205_VpdQ', 'Var144', 'Var7', 'Var188',\n",
    "       'Var35', 'Var25', 'Var65', 'Var21', 'Var195_taul', 'Var133', 'Var22',\n",
    "       'Var212_XfqtO3UdzaXh_', 'Var205_09_Q', 'Var218_UYBR', 'Var228_OTHER',\n",
    "       'Var107', 'Var226_szEZ', 'Var199_OTHER', 'Var206_OTHER', 'Var85',\n",
    "       'Var229_am7c', 'Var204_m_h1', 'Var216_mAjbk_S', 'Var226_3Cy4', 'Var82',\n",
    "       'Var219_FzaX', 'Var72', 'Var226_wX53', 'Var117', 'Var197_lK27',\n",
    "       'Var226_me1d', 'Var227_ZI9m', 'Var193_OTHER', 'Var197_TyGl', 'Var84',\n",
    "       'Var226_7P5s', 'Var59', 'Var68', 'Var200_unknown_Var200',\n",
    "       'Var207_me75fM6ugJ', 'Var211_L84s', 'Var226_Qcbd', 'Var206_lVqb',\n",
    "       'Var10', 'Var216_kq0n8Bj', 'Var195_OTHER', 'Var95',\n",
    "       'Var219_unknown_Var219', 'Var152', 'Var154', 'Var223_M_8D',\n",
    "       'Var225_xG3x', 'Var46', 'Var216_kq0aHkC', 'Var139', 'Var211_Mtgm',\n",
    "       'Var214_unknown_Var214', 'Var223_jySVZNlOJy', 'Var36', 'Var198_iJzviRg',\n",
    "       'Var158']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1=[]\n",
    "for i in train_data_1.columns:\n",
    "    if train_data_1[i].dtypes==float:\n",
    "        lst1.append(i)\n",
    "#lst1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def standardize_data(X_train, X_test):\n",
    "    float_feats_train = X_train[lst1]\n",
    "    float_feats_test = X_test[lst1]\n",
    "    scaler = StandardScaler()\n",
    "    X_train_stand = pd.DataFrame(scaler.fit_transform(float_feats_train), columns = lst1, index = X_train.index)\n",
    "    X_test_stand = pd.DataFrame(scaler.transform(float_feats_test), columns = lst1, index = X_test.index)\n",
    "    X_train_stand = pd.merge(X_train_stand, X_train.loc[:, ~X_train.columns.isin(lst1)], left_index=True, right_index=True)\n",
    "    X_test_stand = pd.merge(X_test_stand, X_test.loc[:, ~X_test.columns.isin(lst1)], left_index=True, right_index=True)\n",
    "    return X_train_stand, X_test_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(train_data_1,churn, stratify=churn, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=standardize_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model with feature selection and standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 512\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 183,297\n",
      "Trainable params: 183,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(265, activation='relu', kernel_initializer='he_normal') )\n",
    "#model.add(Dropout(0.8))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal') )\n",
    "model.add(Dropout(0.8))\n",
    "#model.add(Dense(64, activation='relu', kernel_initializer='he_normal') )\n",
    "#model.add(Dropout(0.8))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/8\n",
      "32000/32000 [==============================] - 4s 138us/step - loss: 0.3516 - acc: 0.9147 - val_loss: 0.2559 - val_acc: 0.9293\n",
      "Epoch 2/8\n",
      "32000/32000 [==============================] - 2s 67us/step - loss: 0.2812 - acc: 0.9250 - val_loss: 0.2479 - val_acc: 0.9293\n",
      "Epoch 3/8\n",
      "32000/32000 [==============================] - 2s 67us/step - loss: 0.2719 - acc: 0.9257 - val_loss: 0.2450 - val_acc: 0.9293\n",
      "Epoch 4/8\n",
      "32000/32000 [==============================] - 2s 67us/step - loss: 0.2676 - acc: 0.9257 - val_loss: 0.2435 - val_acc: 0.9293\n",
      "Epoch 5/8\n",
      "32000/32000 [==============================] - 2s 67us/step - loss: 0.2612 - acc: 0.9255 - val_loss: 0.2413 - val_acc: 0.9293\n",
      "Epoch 6/8\n",
      "32000/32000 [==============================] - 2s 67us/step - loss: 0.2600 - acc: 0.9257 - val_loss: 0.2427 - val_acc: 0.9293\n",
      "Epoch 7/8\n",
      "32000/32000 [==============================] - 2s 67us/step - loss: 0.2566 - acc: 0.9259 - val_loss: 0.2408 - val_acc: 0.9293\n",
      "Epoch 8/8\n",
      "32000/32000 [==============================] - 2s 66us/step - loss: 0.2559 - acc: 0.9257 - val_loss: 0.2391 - val_acc: 0.9293\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train.values, y_train.values, batch_size=batch_size, epochs=8, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3287945414543152\n",
      "Test accuracy: 0.9263\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score is 0.6877418307591965\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"ROC-AUC score is {}\".format(metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D CNN model with feature selection and standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_14 (Conv1D)           (None, 100, 128)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,639,169\n",
      "Trainable params: 1,639,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Conv1D(128, 1, input_shape=(input_dim, 1), activation='relu'))\n",
    "#model.add(MaxPooling1D(5))\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    " #model.add(Dense(256, activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    " #model.add(BatchNormalization())\n",
    " #model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/9\n",
      "32000/32000 [==============================] - 58s 2ms/step - loss: 1.3815 - acc: 0.4807 - val_loss: 1.2944 - val_acc: 0.6970\n",
      "Epoch 2/9\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 1.3107 - acc: 0.5284 - val_loss: 1.2587 - val_acc: 0.5628\n",
      "Epoch 3/9\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 1.2927 - acc: 0.5406 - val_loss: 1.2540 - val_acc: 0.5520\n",
      "Epoch 4/9\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 1.2813 - acc: 0.5580 - val_loss: 1.2551 - val_acc: 0.5044\n",
      "Epoch 5/9\n",
      "32000/32000 [==============================] - 53s 2ms/step - loss: 1.2796 - acc: 0.5412 - val_loss: 1.2493 - val_acc: 0.5863\n",
      "Epoch 6/9\n",
      "32000/32000 [==============================] - 53s 2ms/step - loss: 1.2652 - acc: 0.5517 - val_loss: 1.2433 - val_acc: 0.5464\n",
      "Epoch 7/9\n",
      "32000/32000 [==============================] - 55s 2ms/step - loss: 1.2620 - acc: 0.5579 - val_loss: 1.2501 - val_acc: 0.5705\n",
      "Epoch 8/9\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 1.2524 - acc: 0.5677 - val_loss: 1.2510 - val_acc: 0.5340\n",
      "Epoch 9/9\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 1.2649 - acc: 0.5402 - val_loss: 1.2489 - val_acc: 0.6029\n",
      "Test score: 0.6429817202568054\n",
      "Test accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_cnn, y_train, batch_size=batch_size, epochs=9, verbose=1, validation_split=0.2, class_weight={0.: 1.,1.: 15})\n",
    "score = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score is 0.6931501060688309\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_cnn)\n",
    "print(\"ROC-AUC score is {}\".format( metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Taking target variable as appetency</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(train_data_1, appetency, stratify=appetency, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_cv, y_train, y_cv = train_test_split(X_train , y_train , stratify=y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HyperParameter:  {'max_depth': 5, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "random_classifier = RandomForestClassifier()\n",
    "\n",
    "parameters = { 'max_depth':np.arange(5,10),'n_estimators':list(range(75,301,25))}\n",
    "\n",
    "random_grid = GridSearchCV(random_classifier, parameters, cv = 3)\n",
    "\n",
    "random_grid.fit(X_cv, y_cv)\n",
    "\n",
    "print(\"Best HyperParameter: \",random_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=75, n_jobs=-1, oob_score=True, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Random Forest classifier model\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=75,\n",
    "    #criterion='entropy',\n",
    "    max_depth=5,   # expand until all leaves are pure or contain < MIN_SAMPLES_SPLIT samples\n",
    "    #min_samples_split=100,\n",
    "    #min_samples_leaf=50,\n",
    "    #min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,   # number of features to consider when looking for the best split; None: max_features=n_features\n",
    "    max_leaf_nodes=None,   # None: unlimited number of leaf nodes\n",
    "    bootstrap=True,\n",
    "    oob_score=True,   # estimate Out-of-Bag Cross Entropy\n",
    "    n_jobs=-1,   # paralellize over all CPU cores but 2\n",
    "    class_weight='balanced',    # our classes are skewed, but but too skewed\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7398470743012414"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred_probs=rf_model.predict(X_cv)\n",
    "\n",
    "auc=metrics.roc_auc_score(y_cv,rf_pred_probs)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573270507162322"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred_probs=rf_model.predict(X_test)\n",
    "\n",
    "auc=metrics.roc_auc_score(y_test,rf_pred_probs)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var126', 'Var218_cJvF', 'Var218_UYBR', 'Var28', 'Var81', 'Var153',\n",
       "       'Var113', 'Var163', 'Var57', 'Var94', 'Var133', 'Unnamed: 0', 'Var189',\n",
       "       'Var125', 'Var13', 'Var119', 'Var73', 'Var74', 'Var140', 'Var6',\n",
       "       'Var85', 'Var38', 'Var226_FSa2', 'Var226_Qcbd', 'Var72', 'Var204__xpN',\n",
       "       'Var216_TDceha3', 'Var59', 'Var204_7WNq', 'Var149', 'Var225_kG3k',\n",
       "       'Var34', 'Var216_11p4mKe', 'Var144', 'Var37', 'Var104', 'Var134',\n",
       "       'Var105', 'Var207_7M47J5GA0pTYIFxg5uy', 'Var76', 'Var21',\n",
       "       'Var216_kZJyVg2', 'Var160', 'Var188', 'Var109', 'Var199_OTHER',\n",
       "       'Var204_STGZ', 'Var226_453m', 'Var226_Qu4f', 'Var25', 'Var132', 'Var83',\n",
       "       'Var225_xG3x', 'Var123', 'Var194_SEuy', 'Var22', 'Var223_jySVZNlOJy',\n",
       "       'Var112', 'Var226_xb3V', 'Var206_43pnToF', 'Var162', 'Var199_FoJylxy',\n",
       "       'Var226_WqMG', 'Var216_mAjbk_S', 'Var216_7WwuNea', 'Var216_OTHER',\n",
       "       'Var197_TyGl', 'Var51', 'Var221_oslk', 'Var173', 'Var212_NhsEn4L',\n",
       "       'Var207_me75fM6ugJ', 'Var206_sYC_', 'Var212_OTHER', 'Var205_09_Q',\n",
       "       'Var211_L84s', 'Var225_ELof', 'Var205_VpdQ', 'Var204_vzJD',\n",
       "       'Var229_mj86', 'Var65', 'Var68', 'Var182', 'Var222_APgdzOv',\n",
       "       'Var195_LfvqpCtLOY', 'Var219_unknown_Var219', 'Var228_R4y5gQQWY8OodqDV',\n",
       "       'Var171', 'Var203_HLqf', 'Var228_TCU50_Yjmm6GIBZ0lL_', 'Var69',\n",
       "       'Var143', 'Var78', 'Var10', 'Var136', 'Var227_6fzt', 'Var204_DtNL',\n",
       "       'Var228_F2FyR07IdsN7I', 'Var208_kIsH', 'Var204_m_h1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances[:100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1=train_data_1[['Var126', 'Var218_cJvF', 'Var218_UYBR', 'Var28', 'Var81', 'Var153',\n",
    "       'Var113', 'Var163', 'Var57', 'Var94', 'Var133', 'Unnamed: 0', 'Var189',\n",
    "       'Var125', 'Var13', 'Var119', 'Var73', 'Var74', 'Var140', 'Var6',\n",
    "       'Var85', 'Var38', 'Var226_FSa2', 'Var226_Qcbd', 'Var72', 'Var204__xpN',\n",
    "       'Var216_TDceha3', 'Var59', 'Var204_7WNq', 'Var149', 'Var225_kG3k',\n",
    "       'Var34', 'Var216_11p4mKe', 'Var144', 'Var37', 'Var104', 'Var134',\n",
    "       'Var105', 'Var207_7M47J5GA0pTYIFxg5uy', 'Var76', 'Var21',\n",
    "       'Var216_kZJyVg2', 'Var160', 'Var188', 'Var109', 'Var199_OTHER',\n",
    "       'Var204_STGZ', 'Var226_453m', 'Var226_Qu4f', 'Var25', 'Var132', 'Var83',\n",
    "       'Var225_xG3x', 'Var123', 'Var194_SEuy', 'Var22', 'Var223_jySVZNlOJy',\n",
    "       'Var112', 'Var226_xb3V', 'Var206_43pnToF', 'Var162', 'Var199_FoJylxy',\n",
    "       'Var226_WqMG', 'Var216_mAjbk_S', 'Var216_7WwuNea', 'Var216_OTHER',\n",
    "       'Var197_TyGl', 'Var51', 'Var221_oslk', 'Var173', 'Var212_NhsEn4L',\n",
    "       'Var207_me75fM6ugJ', 'Var206_sYC_', 'Var212_OTHER', 'Var205_09_Q',\n",
    "       'Var211_L84s', 'Var225_ELof', 'Var205_VpdQ', 'Var204_vzJD',\n",
    "       'Var229_mj86', 'Var65', 'Var68', 'Var182', 'Var222_APgdzOv',\n",
    "       'Var195_LfvqpCtLOY', 'Var219_unknown_Var219', 'Var228_R4y5gQQWY8OodqDV',\n",
    "       'Var171', 'Var203_HLqf', 'Var228_TCU50_Yjmm6GIBZ0lL_', 'Var69',\n",
    "       'Var143', 'Var78', 'Var10', 'Var136', 'Var227_6fzt', 'Var204_DtNL',\n",
    "       'Var228_F2FyR07IdsN7I', 'Var208_kIsH', 'Var204_m_h1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(train_data_1, appetency , stratify=appetency, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)\n",
    "y_cv.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model with feature selection and standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 512\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_101 (Dense)            (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 183,297\n",
      "Trainable params: 183,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(265, activation='relu', kernel_initializer='he_normal') )\n",
    "#model.add(Dropout(0.8))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal') )\n",
    "model.add(Dropout(0.8))\n",
    "#model.add(Dense(64, activation='relu', kernel_initializer='he_normal') )\n",
    "#model.add(Dropout(0.8))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/8\n",
      "32000/32000 [==============================] - 7s 206us/step - loss: 2.1006 - acc: 0.6509 - val_loss: 1.0561 - val_acc: 0.6459\n",
      "Epoch 2/8\n",
      "32000/32000 [==============================] - 2s 68us/step - loss: 1.3055 - acc: 0.6806 - val_loss: 1.0377 - val_acc: 0.6849\n",
      "Epoch 3/8\n",
      "32000/32000 [==============================] - 2s 69us/step - loss: 1.2002 - acc: 0.6932 - val_loss: 1.0297 - val_acc: 0.6950\n",
      "Epoch 4/8\n",
      "32000/32000 [==============================] - 2s 69us/step - loss: 1.1227 - acc: 0.7052 - val_loss: 1.0037 - val_acc: 0.7087\n",
      "Epoch 5/8\n",
      "32000/32000 [==============================] - 2s 75us/step - loss: 1.0853 - acc: 0.6960 - val_loss: 1.0242 - val_acc: 0.7037\n",
      "Epoch 6/8\n",
      "32000/32000 [==============================] - 2s 72us/step - loss: 1.0327 - acc: 0.7133 - val_loss: 0.9779 - val_acc: 0.6582\n",
      "Epoch 7/8\n",
      "32000/32000 [==============================] - 2s 72us/step - loss: 1.0109 - acc: 0.7129 - val_loss: 0.9773 - val_acc: 0.7236\n",
      "Epoch 8/8\n",
      "32000/32000 [==============================] - 2s 75us/step - loss: 0.9785 - acc: 0.7285 - val_loss: 0.9871 - val_acc: 0.7242\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train.values, y_train.values, batch_size=batch_size, epochs=8, verbose=1, validation_split=0.2, class_weight={0.: 1.,1.: 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4688142900466919\n",
      "Test accuracy: 0.7275\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score is 0.8170908462772176\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"ROC-AUC score is {}\".format(metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D CNN model with feature selection and standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 100, 128)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,639,169\n",
      "Trainable params: 1,639,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Conv1D(128, 1, input_shape=(input_dim, 1), activation='relu'))\n",
    "#model.add(MaxPooling1D(5))\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    " #model.add(Dense(256, activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    " #model.add(BatchNormalization())\n",
    " #model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/9\n",
      "32000/32000 [==============================] - 57s 2ms/step - loss: 1.3488 - acc: 0.6497 - val_loss: 1.2272 - val_acc: 0.6332\n",
      "Epoch 2/9\n",
      "32000/32000 [==============================] - 57s 2ms/step - loss: 1.1252 - acc: 0.6667 - val_loss: 1.1317 - val_acc: 0.7076\n",
      "Epoch 3/9\n",
      "32000/32000 [==============================] - 56s 2ms/step - loss: 1.0895 - acc: 0.6739 - val_loss: 1.0756 - val_acc: 0.6970\n",
      "Epoch 4/9\n",
      "32000/32000 [==============================] - 63s 2ms/step - loss: 1.0449 - acc: 0.6885 - val_loss: 1.0709 - val_acc: 0.6650\n",
      "Epoch 5/9\n",
      "32000/32000 [==============================] - 48s 2ms/step - loss: 1.0320 - acc: 0.6786 - val_loss: 1.0990 - val_acc: 0.6075\n",
      "Epoch 6/9\n",
      "32000/32000 [==============================] - 48s 1ms/step - loss: 1.0112 - acc: 0.6866 - val_loss: 1.0392 - val_acc: 0.6340\n",
      "Epoch 7/9\n",
      "32000/32000 [==============================] - 48s 2ms/step - loss: 0.9859 - acc: 0.6935 - val_loss: 1.0544 - val_acc: 0.6719\n",
      "Epoch 8/9\n",
      "32000/32000 [==============================] - 56s 2ms/step - loss: 0.9747 - acc: 0.7085 - val_loss: 1.1011 - val_acc: 0.6246\n",
      "Epoch 9/9\n",
      "32000/32000 [==============================] - 53s 2ms/step - loss: 0.9859 - acc: 0.7061 - val_loss: 1.0709 - val_acc: 0.7609\n",
      "Test score: 0.4348352416992188\n",
      "Test accuracy: 0.7587\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_cnn, y_train, batch_size=batch_size, epochs=9, verbose=1, validation_split=0.2, class_weight={0.: 1.,1.: 50})\n",
    "score = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score is 0.8076606288565682\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_cnn)\n",
    "print(\"ROC-AUC score is {}\".format( metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking target variable as Upselling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(train_data_1, upselling, stratify=upselling, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_cv, y_train, y_cv = train_test_split(X_train , y_train , stratify=y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HyperParameter:  {'max_depth': 5, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "random_classifier = RandomForestClassifier()\n",
    "\n",
    "parameters = { 'max_depth':np.arange(5,10),'n_estimators':list(range(75,301,25))}\n",
    "\n",
    "random_grid = GridSearchCV(random_classifier, parameters, cv = 3)\n",
    "\n",
    "random_grid.fit(X_cv, y_cv)\n",
    "\n",
    "print(\"Best HyperParameter: \",random_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features=None,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=75, n_jobs=-1, oob_score=True, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=75,\n",
    "    #criterion='entropy',\n",
    "    max_depth=5,   # expand until all leaves are pure or contain < MIN_SAMPLES_SPLIT samples\n",
    "    #min_samples_split=100,\n",
    "    #min_samples_leaf=50,\n",
    "    #min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,   # number of features to consider when looking for the best split; None: max_features=n_features\n",
    "    max_leaf_nodes=None,   # None: unlimited number of leaf nodes\n",
    "    bootstrap=True,\n",
    "    oob_score=True,   # estimate Out-of-Bag Cross Entropy\n",
    "    n_jobs=-1,   # paralellize over all CPU cores but 2\n",
    "    class_weight='balanced',    # our classes are skewed, but but too skewed\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7572707160626417"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred_probs=rf_model.predict(X_cv)\n",
    "\n",
    "auc=metrics.roc_auc_score(y_cv,rf_pred_probs)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7475911898325449"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred_probs=rf_model.predict(X_test)\n",
    "\n",
    "auc=metrics.roc_auc_score(y_test,rf_pred_probs)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var126', 'Var28', 'Var153', 'Var225_ELof', 'Var6', 'Var226_FSa2',\n",
       "       'Var113', 'Var38', 'Var218_UYBR', 'Var133', 'Var13', 'Var163', 'Var134',\n",
       "       'Var81', 'Unnamed: 0', 'Var211_L84s', 'Var183', 'Var119', 'Var94',\n",
       "       'Var26', 'Var76', 'Var57', 'Var73', 'Var125', 'Var61', 'Var135',\n",
       "       'Var140', 'Var219_FzaX', 'Var149', 'Var74', 'Var16', 'Var102',\n",
       "       'Var210_uKAI', 'Var97', 'Var85', 'Var218_cJvF', 'Var44', 'Var7',\n",
       "       'Var43', 'Var24', 'Var173', 'Var25', 'Var225_kG3k', 'Var204_RVjC',\n",
       "       'Var51', 'Var196_z3mO', 'Var197_OTHER', 'Var228_R4y5gQQWY8OodqDV',\n",
       "       'Var216_NGZxnJM', 'Var109', 'Var189', 'Var204_DtNL', 'Var78', 'Var107',\n",
       "       'Var216_kq0n8Bj', 'Var22', 'Var112', 'Var10', 'Var216_beK4AFX',\n",
       "       'Var166', 'Var206_zm5i', 'Var144', 'Var165', 'Var123', 'Var193_2Knk1KF',\n",
       "       'Var132', 'Var83', 'Var211_Mtgm', 'Var197_TyGl', 'Var226_xb3V',\n",
       "       'Var229_mj86', 'Var226_7P5s', 'Var157', 'Var216_mAja5EA', 'Var5',\n",
       "       'Var219_OFWH', 'Var72', 'Var160', 'Var204_m_h1', 'Var223_LM8l689qOp',\n",
       "       'Var226_5Acm', 'Var216_kZJtVhC', 'Var172', 'Var35', 'Var196_1K8T',\n",
       "       'Var96', 'Var216_OTHER', 'Var206_IYzP', 'Var194_SEuy', 'Var193_RO12',\n",
       "       'Var188', 'Var216_7WwuNea', 'Var65', 'Var33', 'Var227_vJ_w8kB',\n",
       "       'Var226_uWr3', 'Var216_kZJyVg2', 'Var206_unknown_Var206', 'Var197_lK27',\n",
       "       'Var221_zCkv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances[:100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1=train_data_1[['Var126', 'Var28', 'Var153', 'Var225_ELof', 'Var6', 'Var226_FSa2',\n",
    "       'Var113', 'Var38', 'Var218_UYBR', 'Var133', 'Var13', 'Var163', 'Var134',\n",
    "       'Var81', 'Unnamed: 0', 'Var211_L84s', 'Var183', 'Var119', 'Var94',\n",
    "       'Var26', 'Var76', 'Var57', 'Var73', 'Var125', 'Var61', 'Var135',\n",
    "       'Var140', 'Var219_FzaX', 'Var149', 'Var74', 'Var16', 'Var102',\n",
    "       'Var210_uKAI', 'Var97', 'Var85', 'Var218_cJvF', 'Var44', 'Var7',\n",
    "       'Var43', 'Var24', 'Var173', 'Var25', 'Var225_kG3k', 'Var204_RVjC',\n",
    "       'Var51', 'Var196_z3mO', 'Var197_OTHER', 'Var228_R4y5gQQWY8OodqDV',\n",
    "       'Var216_NGZxnJM', 'Var109', 'Var189', 'Var204_DtNL', 'Var78', 'Var107',\n",
    "       'Var216_kq0n8Bj', 'Var22', 'Var112', 'Var10', 'Var216_beK4AFX',\n",
    "       'Var166', 'Var206_zm5i', 'Var144', 'Var165', 'Var123', 'Var193_2Knk1KF',\n",
    "       'Var132', 'Var83', 'Var211_Mtgm', 'Var197_TyGl', 'Var226_xb3V',\n",
    "       'Var229_mj86', 'Var226_7P5s', 'Var157', 'Var216_mAja5EA', 'Var5',\n",
    "       'Var219_OFWH', 'Var72', 'Var160', 'Var204_m_h1', 'Var223_LM8l689qOp',\n",
    "       'Var226_5Acm', 'Var216_kZJtVhC', 'Var172', 'Var35', 'Var196_1K8T',\n",
    "       'Var96', 'Var216_OTHER', 'Var206_IYzP', 'Var194_SEuy', 'Var193_RO12',\n",
    "       'Var188', 'Var216_7WwuNea', 'Var65', 'Var33', 'Var227_vJ_w8kB',\n",
    "       'Var226_uWr3', 'Var216_kZJyVg2', 'Var206_unknown_Var206', 'Var197_lK27',\n",
    "       'Var221_zCkv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(train_data_1, upselling , stratify=upselling, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace(-1, 0, inplace=True)\n",
    "y_test.replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model with feature selection and standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 512\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_106 (Dense)            (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 183,297\n",
      "Trainable params: 183,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(265, activation='relu', kernel_initializer='he_normal') )\n",
    "#model.add(Dropout(0.8))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal') )\n",
    "model.add(Dropout(0.8))\n",
    "#model.add(Dense(64, activation='relu', kernel_initializer='he_normal') )\n",
    "#model.add(Dropout(0.8))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/8\n",
      "32000/32000 [==============================] - 7s 214us/step - loss: 1.5517 - acc: 0.6031 - val_loss: 1.0766 - val_acc: 0.6029\n",
      "Epoch 2/8\n",
      "32000/32000 [==============================] - 2s 76us/step - loss: 1.1475 - acc: 0.6319 - val_loss: 1.0378 - val_acc: 0.6614\n",
      "Epoch 3/8\n",
      "32000/32000 [==============================] - 3s 83us/step - loss: 1.0693 - acc: 0.6613 - val_loss: 1.0030 - val_acc: 0.6367\n",
      "Epoch 4/8\n",
      "32000/32000 [==============================] - 3s 83us/step - loss: 1.0383 - acc: 0.6718 - val_loss: 0.9844 - val_acc: 0.6640\n",
      "Epoch 5/8\n",
      "32000/32000 [==============================] - 3s 79us/step - loss: 1.0005 - acc: 0.6882 - val_loss: 0.9702 - val_acc: 0.7146\n",
      "Epoch 6/8\n",
      "32000/32000 [==============================] - 3s 89us/step - loss: 0.9812 - acc: 0.7034 - val_loss: 0.9623 - val_acc: 0.7001\n",
      "Epoch 7/8\n",
      "32000/32000 [==============================] - 4s 125us/step - loss: 0.9574 - acc: 0.7231 - val_loss: 0.9588 - val_acc: 0.7197\n",
      "Epoch 8/8\n",
      "32000/32000 [==============================] - 2s 71us/step - loss: 0.9437 - acc: 0.7242 - val_loss: 0.9515 - val_acc: 0.7229\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train.values, y_train.values, batch_size=batch_size, epochs=8, verbose=1, validation_split=0.2, class_weight={0.: 1.,1.: 13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.5093770072937012\n",
      "Test accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score is 0.8088366256476685\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"ROC-AUC score is {}\".format(metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D CNN model with feature selection and standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 100, 128)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 256)               1638656   \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,639,169\n",
      "Trainable params: 1,639,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Conv1D(128, 1, input_shape=(input_dim, 1), activation='relu'))\n",
    "#model.add(MaxPooling1D(5))\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    " #model.add(Dense(256, activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    " #model.add(BatchNormalization())\n",
    " #model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/19\n",
      "32000/32000 [==============================] - 57s 2ms/step - loss: 0.2685 - acc: 0.9157 - val_loss: 0.2270 - val_acc: 0.9279\n",
      "Epoch 2/19\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 0.2290 - acc: 0.9260 - val_loss: 0.2223 - val_acc: 0.9279\n",
      "Epoch 3/19\n",
      "32000/32000 [==============================] - 52s 2ms/step - loss: 0.2249 - acc: 0.9260 - val_loss: 0.2198 - val_acc: 0.9279\n",
      "Epoch 4/19\n",
      "32000/32000 [==============================] - 53s 2ms/step - loss: 0.2251 - acc: 0.9260 - val_loss: 0.2190 - val_acc: 0.9279\n",
      "Epoch 5/19\n",
      "32000/32000 [==============================] - 58s 2ms/step - loss: 0.2240 - acc: 0.9260 - val_loss: 0.2215 - val_acc: 0.9279\n",
      "Epoch 6/19\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 0.2235 - acc: 0.9260 - val_loss: 0.2211 - val_acc: 0.9279\n",
      "Epoch 7/19\n",
      "32000/32000 [==============================] - 59s 2ms/step - loss: 0.2210 - acc: 0.9260 - val_loss: 0.2171 - val_acc: 0.9279\n",
      "Epoch 8/19\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 0.2197 - acc: 0.9260 - val_loss: 0.2154 - val_acc: 0.9279\n",
      "Epoch 9/19\n",
      "32000/32000 [==============================] - 52s 2ms/step - loss: 0.2195 - acc: 0.9259 - val_loss: 0.2144 - val_acc: 0.9279\n",
      "Epoch 10/19\n",
      "32000/32000 [==============================] - 51s 2ms/step - loss: 0.2180 - acc: 0.9260 - val_loss: 0.2138 - val_acc: 0.9279\n",
      "Epoch 11/19\n",
      "32000/32000 [==============================] - 51s 2ms/step - loss: 0.2176 - acc: 0.9259 - val_loss: 0.2133 - val_acc: 0.9277\n",
      "Epoch 12/19\n",
      "32000/32000 [==============================] - 52s 2ms/step - loss: 0.2159 - acc: 0.9261 - val_loss: 0.2131 - val_acc: 0.9279\n",
      "Epoch 13/19\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 0.2151 - acc: 0.9261 - val_loss: 0.2102 - val_acc: 0.9281\n",
      "Epoch 14/19\n",
      "32000/32000 [==============================] - 52s 2ms/step - loss: 0.2151 - acc: 0.9267 - val_loss: 0.2091 - val_acc: 0.9283\n",
      "Epoch 15/19\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 0.2136 - acc: 0.9273 - val_loss: 0.2088 - val_acc: 0.9284\n",
      "Epoch 16/19\n",
      "32000/32000 [==============================] - 63s 2ms/step - loss: 0.2121 - acc: 0.9286 - val_loss: 0.2137 - val_acc: 0.9334\n",
      "Epoch 17/19\n",
      "32000/32000 [==============================] - 55s 2ms/step - loss: 0.2109 - acc: 0.9292 - val_loss: 0.2072 - val_acc: 0.9293\n",
      "Epoch 18/19\n",
      "32000/32000 [==============================] - 55s 2ms/step - loss: 0.2092 - acc: 0.9301 - val_loss: 0.2053 - val_acc: 0.9310\n",
      "Epoch 19/19\n",
      "32000/32000 [==============================] - 54s 2ms/step - loss: 0.2084 - acc: 0.9297 - val_loss: 0.2043 - val_acc: 0.9335\n",
      "Test score: 0.20780178388357162\n",
      "Test accuracy: 0.9336\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_cnn, y_train, batch_size=batch_size, epochs=19, verbose=1, validation_split=0.2, class_weight={0.: 1.,1.: 1})\n",
    "score = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score is 0.8018233713251859\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_cnn)\n",
    "print(\"ROC-AUC score is {}\".format( metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+----------+\n",
      "|  Model Name  | Target Variable | Test AUC |\n",
      "+--------------+-----------------+----------+\n",
      "|  MLP model   |      churn      |  0.687   |\n",
      "| 1D CNN model |      churn      |  0.693   |\n",
      "|  MLP model   |    appetency    |  0.817   |\n",
      "| 1D CNN model |    appetency    |  0.807   |\n",
      "|  MLP model   |    upselling    |  0.808   |\n",
      "| 1D CNN model |    upselling    |  0.801   |\n",
      "+--------------+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Model Name\", \"Target Variable\", \"Test AUC\"]\n",
    "x.add_row(['MLP model','churn','0.687'])\n",
    "x.add_row(['1D CNN model','churn','0.693'])\n",
    "x.add_row(['MLP model','appetency','0.817'])\n",
    "x.add_row(['1D CNN model','appetency','0.807'])\n",
    "x.add_row(['MLP model','upselling','0.808'])\n",
    "x.add_row(['1D CNN model','upselling','0.801'])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to be followed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Acquiring the dataset.\n",
    "2. Clean the dataset and get it into a format convenient for analysis.\n",
    "3. Summarizing and visualizing important characteristics and statistical properties of the dataset.\n",
    "4. Building models to predict the customer relationship behaviour, evaluate the results of models, and eventually, choose the best suitable predictive model ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refereces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/asminalev/kddcup-2009-data-analysis\n",
    "* https://github.com/jjmanrique/KDD-Cup-2009/blob/master/KDD_small.ipynb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
